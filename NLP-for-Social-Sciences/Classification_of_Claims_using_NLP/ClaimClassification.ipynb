{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the training data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = 'train-data-prepared.json'\n",
    "val_data_file = 'val-data-prepared.json'\n",
    "\n",
    "df_train = pd.read_json(train_data_file)\n",
    "df_val = pd.read_json(val_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Pre-process the text(lower casing, lead/train space stripping,remove punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PreprocessData(df):\n",
    "    df['clean_text'] = df['text'].str.lower()\n",
    "    df['clean_text'] = df['clean_text'].str.strip()\n",
    "    df['clean_text'] = df['clean_text'].str.replace(r\"http\\S+\",'')\n",
    "    df['clean_text'] = df['clean_text'].str.replace('[^\\w\\s]','')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Linguistic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureExtract(df):\n",
    "    md_exist_list = [] # modal verb\n",
    "    verb_exist_list = [] # verb\n",
    "    prp_exist_list = [] # personal pronouns\n",
    "    vbp_exist_list = [] # verb non 3rd person\n",
    "    adv_exist_list = [] # adverb\n",
    "    conj_exist_list = [] #conjunction/preposition\n",
    "    adj_exist_list = [] #adjective\n",
    "    disc_exist_list = [] # discourse markers\n",
    "\n",
    "    for text in df['clean_text']:\n",
    "        doc = nlp(text)\n",
    "        md_exist = 0\n",
    "        verb_exist = 0\n",
    "        prp_exist = 0\n",
    "        vbp_exist = 0\n",
    "        adv_exist = 0\n",
    "        conj_exist = 0\n",
    "        adj_exist = 0\n",
    "        disc_exist = 0\n",
    "\n",
    "        for token in doc:\n",
    "            if token.tag_ == 'MD':\n",
    "                md_exist = 1\n",
    "\n",
    "            if token.pos_ == 'VERB':\n",
    "                verb_exist = 1\n",
    "\n",
    "            if token.tag_ == 'PRP':\n",
    "                prp_exist = 1\n",
    "\n",
    "            if token.tag_ == 'VBP':\n",
    "                vbp_exist = 1\n",
    "\n",
    "            if token.pos_ == 'ADV':\n",
    "                adv_exist = 1\n",
    "            \n",
    "            if token.dep_ == 'prep':\n",
    "                conj_exist = 1\n",
    "            \n",
    "            if token.pos_ == 'ADJ':\n",
    "                adj_exist = 1\n",
    "            \n",
    "            if token.tag_ == 'IN' and token.pos_!='ADP':\n",
    "                disc_exist = 1\n",
    "\n",
    "        md_exist_list.append(md_exist)\n",
    "        verb_exist_list.append(verb_exist)\n",
    "        prp_exist_list.append(prp_exist)\n",
    "        vbp_exist_list.append(vbp_exist)\n",
    "        adv_exist_list.append(adv_exist)\n",
    "        conj_exist_list.append(conj_exist)\n",
    "        adj_exist_list.append(adj_exist)\n",
    "        disc_exist_list.append(disc_exist)\n",
    "\n",
    "    df['modal_exist'] = md_exist_list\n",
    "    df['verb_exist'] = verb_exist_list\n",
    "    df['prp_exist'] = prp_exist_list\n",
    "    df['vbp_exist'] = vbp_exist_list\n",
    "    df['adv_exist'] = adv_exist_list\n",
    "    df['conj_exist'] = conj_exist_list\n",
    "    df['adj_exist'] = adj_exist_list\n",
    "    df['disc_exist'] = disc_exist_list\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1363ac6f16e232a1d8e9343d975ebe10</td>\n",
       "      <td>Since communism has been relegated to just a h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6b925ce5eeb8b690b35972abafcb7c60</td>\n",
       "      <td>Can you counter that?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99977c6e63734add1c1b600be79b3342</td>\n",
       "      <td>Censorship does not eliminate the censored ind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e34d9e198bc9e12f0868793c68d32f0</td>\n",
       "      <td>Without the extra population from abortions, h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629d09668c3339dba831f6c81a307b0e</td>\n",
       "      <td>I can't stand it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>452684ca088e4ab1c58d89e1a28e1ef7</td>\n",
       "      <td>it's \"true\" or not and that \"truth\" is availab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>b5fa34bde09f97ab565ec1ae433d1797</td>\n",
       "      <td>And these slogans don't even denote any sense ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>f676671baa396678dcb3471ea67e70ed</td>\n",
       "      <td>&amp;gt;whole-bodyWhile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>a4e0fa2814bb40ae76750ea1597084de</td>\n",
       "      <td>that the majority of them are affected negativ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>5472aeb15e476c1542ca23ecd9c6e511</td>\n",
       "      <td>And just trying to be romantic with women, ass...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2619 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0     1363ac6f16e232a1d8e9343d975ebe10   \n",
       "1     6b925ce5eeb8b690b35972abafcb7c60   \n",
       "2     99977c6e63734add1c1b600be79b3342   \n",
       "3     7e34d9e198bc9e12f0868793c68d32f0   \n",
       "4     629d09668c3339dba831f6c81a307b0e   \n",
       "...                                ...   \n",
       "2614  452684ca088e4ab1c58d89e1a28e1ef7   \n",
       "2615  b5fa34bde09f97ab565ec1ae433d1797   \n",
       "2616  f676671baa396678dcb3471ea67e70ed   \n",
       "2617  a4e0fa2814bb40ae76750ea1597084de   \n",
       "2618  5472aeb15e476c1542ca23ecd9c6e511   \n",
       "\n",
       "                                                   text  label  \n",
       "0     Since communism has been relegated to just a h...      0  \n",
       "1                                 Can you counter that?      0  \n",
       "2     Censorship does not eliminate the censored ind...      0  \n",
       "3     Without the extra population from abortions, h...      0  \n",
       "4                                      I can't stand it      1  \n",
       "...                                                 ...    ...  \n",
       "2614  it's \"true\" or not and that \"truth\" is availab...      0  \n",
       "2615  And these slogans don't even denote any sense ...      0  \n",
       "2616                               &gt;whole-bodyWhile       0  \n",
       "2617  that the majority of them are affected negativ...      1  \n",
       "2618  And just trying to be romantic with women, ass...      0  \n",
       "\n",
       "[2619 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and feature extraction: Train and Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = PreprocessData(df_train)\n",
    "df_train = FeatureExtract(df_train)\n",
    "\n",
    "df_val = PreprocessData(df_val)\n",
    "df_val = FeatureExtract(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction using Bag of Words(uni and bigrams): Train and Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "feature_matrix_bow = vectorizer.fit_transform(df_train['clean_text'])\n",
    "\n",
    "\n",
    "df_features_bow = pd.DataFrame(feature_matrix_bow.toarray())\n",
    "df_features_text = df_train[[\"modal_exist\",\"verb_exist\",\"prp_exist\",\"vbp_exist\",\"adv_exist\",\"conj_exist\",\"adj_exist\",\n",
    "                             \"disc_exist\"]]\n",
    "df_features = pd.concat([df_features_bow,df_features_text],axis = 1)\n",
    "\n",
    "x_train = df_features.values\n",
    "y_train = df_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Val/Test dataset with the vectorizer object\n",
    "\n",
    "feature_matrix_bow_val = vectorizer.transform(df_val['clean_text'])\n",
    "\n",
    "df_features_bow_val = pd.DataFrame(feature_matrix_bow_val.toarray())\n",
    "df_features_text_val = df_val[[\"modal_exist\",\"verb_exist\",\"prp_exist\",\"vbp_exist\",\"adv_exist\",\"conj_exist\",\"adj_exist\",\n",
    "                              \"disc_exist\"]]\n",
    "df_features_val = pd.concat([df_features_bow_val,df_features_text_val],axis = 1)\n",
    "\n",
    "x_val = df_features_val.values\n",
    "y_val = df_val['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual training with the best hyperparameters combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=20.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(C=10.0, gamma=0.01)\n",
    "# classifier = LogisticRegression(C = 20.0, penalty = 'l2',max_iter=1000)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49781659388646293\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_val)\n",
    "print(metrics.f1_score(y_val,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting IDs -> Generating a dictionary -> Creating a JSON output file with predictions\n",
    "\n",
    "val_data_id = df_val['id'].values\n",
    "pred_val = dict(zip(val_data_id, predictions))\n",
    "\n",
    "with open('pred_out.json', 'w') as fp:\n",
    "    json.dump(pred_val,fp,default=str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
